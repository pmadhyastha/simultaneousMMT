-------
[train]
-------
         num_workers:0
          pin_memory:False
                seed:1588694941
               gclip:1
              l2_reg:1e-05
            patience:10
           optimizer:adam
                  lr:0.0004
            lr_decay:plateau
     lr_decay_revert:False
     lr_decay_factor:0.5
   lr_decay_patience:2
        lr_decay_min:1e-06
          model_type:SimultaneousNMT
            momentum:0.0
            nesterov:False
           disp_freq:30
          batch_size:64
          max_epochs:100
      max_iterations:1000000
        eval_metrics:bleu,loss
        eval_filters:
             de-hyphen
     eval_batch_size:32
           eval_freq:0
        eval_max_len:100
          eval_start:1
           eval_zero:False
   save_best_metrics:True
           save_path:/homes/al4616/experiments/simnmt/nmtpy/w2w_models/de-de
    save_optim_state:False
     checkpoint_freq:5000
       n_checkpoints:0
     tensorboard_dir:/homes/al4616/experiments/simnmt/nmtpy/w2w_models/de-de/tb_dir
     pretrained_file:
   pretrained_layers:
       freeze_layers:
          handle_oom:False
           subfolder:de-de
              exp_id:simultaneousnmt-rd752e
------
[vars]
------
                  sl:en
                  tl:de
-------
[model]
-------
            att_type:mlp
      att_bottleneck:hid
             enc_dim:320
   enc_bidirectional:False
             dec_dim:320
             emb_dim:200
         dropout_emb:0.4
         dropout_ctx:0.5
         dropout_out:0.5
          n_encoders:2
            tied_emb:2way
             max_len:None
           out_logic:deep
           direction:src:Text, image:Numpy -> trg:Text
        sampler_type:bucket
           bucket_by:src
         aux_dropout:0.5
        aux_proj_dim:320
      aux_proj_activ:tanh
             aux_dim:2048
       dec_inp_activ:None
        mm_fusion_op:sum
   mm_fusion_dropout:0.0
------
[data]
------
            txt_root:/vol/bitbucket/al4616/simmt/data/multi30k/en-de
            img_root:/vol/bitbucket/al4616/simmt/data/resnet50-256x256
           train_set:
                   src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/train.lc.norm.tok.de
                 image:/vol/bitbucket/al4616/simmt/data/resnet50-256x256/train-resnet50-res5c_relu-r256-c256-l2norm.npy
                   trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/train.lc.norm.tok.de
             val_set:
                   src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/val.lc.norm.tok.de
                 image:/vol/bitbucket/al4616/simmt/data/resnet50-256x256/val-resnet50-res5c_relu-r256-c256-l2norm.npy
                   trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/val.lc.norm.tok.de
test_2016_flickr_set:
                   src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/test_2016_flickr.lc.norm.tok.de
                 image:/vol/bitbucket/al4616/simmt/data/resnet50-256x256/test_2016_flickr-resnet50-res5c_relu-r256-c256-l2norm.npy
                   trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/test_2016_flickr.lc.norm.tok.de
test_2017_flickr_set:
                   src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/test_2017_flickr.lc.norm.tok.de
                 image:/vol/bitbucket/al4616/simmt/data/resnet50-256x256/test_2017_flickr-resnet50-res5c_relu-r256-c256-l2norm.npy
                   trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/test_2017_flickr.lc.norm.tok.de
------------
[vocabulary]
------------
                 src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/train.lc.norm.tok.vocab.de
                 trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/train.lc.norm.tok.vocab.de
----------------------------------------------------------------------

Python 3.7.7 -- torch 1.4.0 with CUDA 10.1 (on machine 'cloud-vm-40-190.doc.ic.ac.uk')
nmtpytorch 4.1.0
DeviceManager(cuda:0, n_gpu=1)
Seed for further reproducibility: 1588694941
SLURM Job ID: 5548
Loading dataset(s)
Initializing dataset for 'src'...
0sents [00:00, ?sents/s]14377sents [00:00, 142301.42sents/s]28754sents [00:00, 120184.18sents/s]29000sents [00:00, 120319.84sents/s]
Initializing dataset for 'image'...
Initializing dataset for 'trg'...
0sents [00:00, ?sents/s]14917sents [00:00, 149122.86sents/s]29000sents [00:00, 145100.81sents/s]
MultimodalDataset - (2 source(s) / 1 target(s))
  Sampler type: bucket, bucket_by: src
  Sources:
    --> TextDataset 'train.lc.norm.tok.de' (29000 sentences)
    --> NumpyDataset 'train-resnet50-res5c_relu-r256-c256-l2norm.npy' (29000 samples)

  Targets:
    --> TextDataset 'train.lc.norm.tok.de' (29000 sentences)

Initializing dataset for 'src'...
0sents [00:00, ?sents/s]1014sents [00:00, 128969.41sents/s]
Initializing dataset for 'image'...
Initializing dataset for 'trg'...
0sents [00:00, ?sents/s]1014sents [00:00, 137282.90sents/s]
MultimodalDataset - (2 source(s) / 1 target(s))
  Sampler type: bucket, bucket_by: src
  Sources:
    --> TextDataset 'val.lc.norm.tok.de' (1014 sentences)
    --> NumpyDataset 'val-resnet50-res5c_relu-r256-c256-l2norm.npy' (1014 samples)

  Targets:
    --> TextDataset 'val.lc.norm.tok.de' (1014 sentences)

Initializing dataset for 'src'...
0sents [00:00, ?sents/s]1014sents [00:00, 141999.41sents/s]
Initializing dataset for 'image'...
Skipping 'trg' as target
MultimodalDataset - (2 source(s) / 0 target(s))
  Sampler type: bucket, bucket_by: src
  Sources:
    --> TextDataset 'val.lc.norm.tok.de' (1014 sentences)
    --> NumpyDataset 'val-resnet50-res5c_relu-r256-c256-l2norm.npy' (1014 samples)


SimultaneousNMT(
  (encoders): ModuleDict(
    (image): VisualFeaturesEncoder(
      (output): Sequential(
        (0): FF(in_features=2048, out_features=320, activ=tanh, bias=True, bias_zero=True)
        (1): Dropout(p=0.5, inplace=False)
      )
    )
    (src): TextEncoder(
      (do_emb): Dropout(p=0.4, inplace=False)
      (emb): Embedding(18050, 200, padding_idx=0)
      (enc): GRU(200, 320, num_layers=2)
      (output): Sequential(
        (0): Dropout(p=0.5, inplace=False)
      )
    )
  )
  (dec): SimultaneousConditionalDecoder(
    (emb): Embedding(18050, 200, padding_idx=0)
    (att): ModuleDict(
      (image): MLPAttention(
        (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
        (mlp): Linear(in_features=320, out_features=1, bias=False)
      )
      (src): MLPAttention(
        (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
        (mlp): Linear(in_features=320, out_features=1, bias=False)
      )
    )
    (fusion): Sequential(
      (0): Fusion(type=sum, adaptor=<function Fusion.__init__.<locals>.<lambda> at 0x7fe8a49a77a0>, activ=None)
    )
    (dec0): GRUCell(200, 320)
    (dec1): GRUCell(320, 320)
    (do_out): Dropout(p=0.5, inplace=False)
    (hid2out): FF(in_features=840, out_features=200, activ=tanh, bias=True, bias_zero=True)
    (out2prob): FF(in_features=200, out_features=18050, activ=linear, bias=True, bias_zero=True)
    (nll_loss): NLLLoss()
  )
)
Vocabulary of 18050 items ('train.lc.norm.tok.vocab.de')
Vocabulary of 18050 items ('train.lc.norm.tok.vocab.de')
# parameters: 10.91M (10.91M learnable)

Optimizer => adam (lr: 0.0004, weight_decay: 1e-05, g_clip: 1, lr_decay: (patience=2, factor=0.5))
TensorBoard is active
Training started on 05-05-2020 17:09:21
Starting Epoch 1
Epoch 1 - update         30 => loss:   6.765 (#OOM: 0)
Epoch 1 - update         60 => loss:   5.768 (#OOM: 0)
Epoch 1 - update         90 => loss:   5.636 (#OOM: 0)
Epoch 1 - update        120 => loss:   4.906 (#OOM: 0)
Epoch 1 - update        150 => loss:   4.549 (#OOM: 0)
Epoch 1 - update        180 => loss:   4.647 (#OOM: 0)
Epoch 1 - update        210 => loss:   4.940 (#OOM: 0)
Epoch 1 - update        240 => loss:   4.027 (#OOM: 0)
Epoch 1 - update        270 => loss:   3.752 (#OOM: 0)
Epoch 1 - update        300 => loss:   4.245 (#OOM: 0)
Epoch 1 - update        330 => loss:   4.033 (#OOM: 0)
Epoch 1 - update        360 => loss:   3.555 (#OOM: 0)
Epoch 1 - update        390 => loss:   4.443 (#OOM: 0)
Epoch 1 - update        420 => loss:   3.028 (#OOM: 0)
Epoch 1 - update        450 => loss:   3.409 (#OOM: 0)
--> Epoch 1 finished with mean loss 4.83953
--> Overhead/Training/Evaluation: 0.65/0.52/0.00 mins (total: 1.17 mins)   (933 samples/sec)
Computing evaluation loss...
  0%|                                       | 0/38 [00:00<?, ?batch/s]  0%|                                       | 0/38 [00:00<?, ?batch/s]
Traceback (most recent call last):
  File "/vol/bitbucket/al4616/miniconda3/envs/simnmt/bin/nmtpy", line 7, in <module>
    exec(compile(f.read(), __file__, 'exec'))
  File "/vol/bitbucket/al4616/simmt/bin/nmtpy", line 135, in <module>
    loop()
  File "/vol/bitbucket/al4616/simmt/nmtpytorch/mainloop.py", line 310, in __call__
    while self.train_epoch():
  File "/vol/bitbucket/al4616/simmt/nmtpytorch/mainloop.py", line 246, in train_epoch
    self.do_validation()
  File "/vol/bitbucket/al4616/simmt/nmtpytorch/mainloop.py", line 265, in do_validation
    results.extend(self.net.test_performance(self.vloss_iterator))
  File "/vol/bitbucket/al4616/simmt/nmtpytorch/models/snmt.py", line 275, in test_performance
    out = self.forward(batch)
  File "/vol/bitbucket/al4616/simmt/nmtpytorch/models/snmt.py", line 261, in forward
    log_p, h = self.dec.f_next(state_dict, y_emb[t], h)
  File "/vol/bitbucket/al4616/simmt/nmtpytorch/layers/decoders/sconditional.py", line 132, in f_next
    self.history[f'alpha_{k}'].append(att)
  File "/vol/bitbucket/al4616/miniconda3/envs/simnmt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 576, in __getattr__
    type(self).__name__, name))
AttributeError: 'SimultaneousConditionalDecoder' object has no attribute 'history'

Tue May  5 17:10:32 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:00:07.0 Off |                    0 |
| N/A   50C    P0    29W /  70W |      0MiB / 15109MiB |     22%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
 17:10:32 up 18 days,  5:14,  3 users,  load average: 15.81, 12.53, 10.90
