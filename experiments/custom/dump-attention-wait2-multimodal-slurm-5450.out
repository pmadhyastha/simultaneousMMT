-- disable_filters -> False
-- batch_size -> 16
-- max_len -> 100
-- device_id -> gpu
-- override -> []
-- stochastic -> False
-- splits -> test_2016_flickr
-- source -> None
-- output -> wait2_multimodal_decoding_results
-- func -> vwk
-- delta -> 
-- n_init_tokens -> 1,2,3,5,7
-- criteria -> 
-- model -> ../experiments/simultaneouswaitknmt-rc85df.best.bleu.ckpt
STranslator: setting batch_size=1 for 'vwk' decoding
SimultaneousWaitKNMT(
  (encoders): ModuleDict(
    (image): VisualFeaturesEncoder(
      (output): Sequential(
        (0): FF(in_features=2048, out_features=320, activ=tanh, bias=True, bias_zero=True)
        (1): Dropout(p=0.5, inplace=False)
      )
    )
    (src): TextEncoder(
      (do_emb): Dropout(p=0.4, inplace=False)
      (emb): Embedding(9797, 200, padding_idx=0)
      (enc): GRU(200, 320, num_layers=2)
      (output): Sequential(
        (0): Dropout(p=0.5, inplace=False)
      )
    )
  )
  (dec): SimultaneousConditionalDecoder(
    (emb): Embedding(7875, 200, padding_idx=0)
    (att): ModuleDict(
      (image): MLPAttention(
        (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
        (mlp): Linear(in_features=320, out_features=1, bias=False)
      )
      (src): MLPAttention(
        (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
        (mlp): Linear(in_features=320, out_features=1, bias=False)
      )
    )
    (fusion): Sequential(
      (0): Fusion(type=sum, adaptor=<function Fusion.__init__.<locals>.<lambda> at 0x7fc8a93e7d40>, activ=None)
    )
    (dec0): GRUCell(200, 320)
    (dec1): GRUCell(320, 320)
    (do_out): Dropout(p=0.5, inplace=False)
    (hid2out): FF(in_features=840, out_features=200, activ=tanh, bias=True, bias_zero=True)
    (out2prob): FF(in_features=200, out_features=7875, activ=linear, bias=True, bias_zero=True)
    (nll_loss): NLLLoss()
  )
)
Vocabulary of 9797 items ('train.lc.norm.tok.vocab.en')
Vocabulary of 7875 items ('train.lc.norm.tok-min2.vocab.de')
# parameters: 7.22M (7.22M learnable)

Post-processing filters enabled.
Will translate "['test_2016_flickr']"
Initializing dataset for 'src'...
0sents [00:00, ?sents/s]1000sents [00:00, 118946.85sents/s]
Initializing dataset for 'image'...
Skipping 'trg' as target
MultimodalDataset - (2 source(s) / 0 target(s))
  Sampler type: bucket, bucket_by: src
  Sources:
    --> TextDataset 'test_2016_flickr.lc.norm.tok.en' (1000 sentences)
    --> NumpyDataset 'test_2016_flickr-resnet50-res5c_relu-r256-c256-l2norm.npy' (1000 samples)


Ignoring batch_size 1 for simultaneous greedy search
Starting translation for 'test_2016_flickr'
  0%|                                     | 0/1000 [00:00<?, ?batch/s]  0%|                                     | 0/1000 [00:00<?, ?batch/s]
decoder attrs
{'training': False, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_backward_hooks': OrderedDict(), '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('emb', Embedding(7875, 200, padding_idx=0)), ('att', ModuleDict(
  (image): MLPAttention(
    (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
    (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
    (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
    (mlp): Linear(in_features=320, out_features=1, bias=False)
  )
  (src): MLPAttention(
    (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
    (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
    (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
    (mlp): Linear(in_features=320, out_features=1, bias=False)
  )
)), ('fusion', Sequential(
  (0): Fusion(type=sum, adaptor=<function Fusion.__init__.<locals>.<lambda> at 0x7fc8a93e7d40>, activ=None)
)), ('dec0', GRUCell(200, 320)), ('dec1', GRUCell(320, 320)), ('do_out', Dropout(p=0.5, inplace=False)), ('hid2out', FF(in_features=840, out_features=200, activ=tanh, bias=True, bias_zero=True)), ('out2prob', FF(in_features=200, out_features=7875, activ=linear, bias=True, bias_zero=True)), ('nll_loss', NLLLoss())]), 'rnn_type': 'GRU', 'input_size': 200, 'hidden_size': 320, 'n_vocab': 7875, 'dec_inp_activ_fn': <function get_activation_fn.<locals>.<lambda> at 0x7fc8a9434050>, 'out_merge_fn': <function SimultaneousConditionalDecoder.__init__.<locals>.<lambda> at 0x7fc8a93ec050>}
attention layers
ModuleDict(
  (image): MLPAttention(
    (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
    (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
    (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
    (mlp): Linear(in_features=320, out_features=1, bias=False)
  )
  (src): MLPAttention(
    (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
    (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
    (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
    (mlp): Linear(in_features=320, out_features=1, bias=False)
  )
)
{'training': False, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_backward_hooks': OrderedDict(), '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('image', MLPAttention(
  (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
  (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
  (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
  (mlp): Linear(in_features=320, out_features=1, bias=False)
)), ('src', MLPAttention(
  (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
  (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
  (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
  (mlp): Linear(in_features=320, out_features=1, bias=False)
))])}
Traceback (most recent call last):
  File "/vol/bitbucket/al4616/miniconda3/envs/simnmt/bin/nmtpy", line 7, in <module>
    exec(compile(f.read(), __file__, 'exec'))
  File "/vol/bitbucket/al4616/simmt/bin/nmtpy", line 100, in <module>
    stranslator()
  File "/vol/bitbucket/al4616/simmt/nmtpytorch/stranslator.py", line 129, in __call__
    self.translate(input_)
  File "/vol/bitbucket/al4616/simmt/nmtpytorch/stranslator.py", line 125, in translate
    translator.run_all()
  File "/vol/bitbucket/al4616/simmt/nmtpytorch/translators/verbose_waitk_greedy.py", line 21, in run_all
    hyps, actions, attentions, up_time = self.run(int(k))
  File "/vol/bitbucket/al4616/simmt/nmtpytorch/translators/verbose_waitk_greedy.py", line 101, in run
    tatt = self.model.dec.history['alpha_txt'][-1].data.clone().numpy()
  File "/vol/bitbucket/al4616/miniconda3/envs/simnmt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 576, in __getattr__
    type(self).__name__, name))
AttributeError: 'SimultaneousConditionalDecoder' object has no attribute 'history'

Sun May  3 17:46:57 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN Xp            On   | 00000000:1E:00.0 Off |                  N/A |
| 23%   37C    P0    61W / 250W |      0MiB / 12196MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
 17:46:57 up 122 days,  3:01,  4 users,  load average: 14.64, 13.72, 14.15
