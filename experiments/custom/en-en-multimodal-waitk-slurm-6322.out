-------
[train]
-------
         num_workers:0
          pin_memory:False
                seed:1590005827
               gclip:1
              l2_reg:1e-05
            patience:10
           optimizer:adam
                  lr:0.0004
            lr_decay:plateau
     lr_decay_revert:False
     lr_decay_factor:0.5
   lr_decay_patience:2
        lr_decay_min:1e-06
          model_type:SimultaneousWaitKNMT
            momentum:0.0
            nesterov:False
           disp_freq:30
          batch_size:64
          max_epochs:100
      max_iterations:1000000
        eval_metrics:bleu,loss
        eval_filters:
             de-hyphen
     eval_batch_size:32
           eval_freq:0
        eval_max_len:100
          eval_start:1
           eval_zero:False
   save_best_metrics:True
           save_path:/homes/al4616/experiments/simnmt/nmtpy/bpe_models/en-en
    save_optim_state:False
     checkpoint_freq:5000
       n_checkpoints:0
     tensorboard_dir:/homes/al4616/experiments/simnmt/nmtpy/bpe_models/en-en/tb_dir
     pretrained_file:
   pretrained_layers:
       freeze_layers:
          handle_oom:False
           subfolder:en-en-multimodal-w2bpe-wait1
              exp_id:simultaneouswaitknmt-r2d153
------
[vars]
------
                  sl:en
                  tl:de
-------
[model]
-------
            att_type:mlp
      att_bottleneck:hid
             enc_dim:320
   enc_bidirectional:False
             dec_dim:320
             emb_dim:200
         dropout_emb:0.4
         dropout_ctx:0.5
         dropout_out:0.5
          n_encoders:2
            tied_emb:2way
             max_len:None
           out_logic:deep
           direction:src:Text, image:Numpy -> trg:Text
        sampler_type:bucket
           bucket_by:src
     translator_args:
                     k:1
         aux_dropout:0.5
        aux_proj_dim:320
      aux_proj_activ:tanh
             aux_dim:2048
       dec_inp_activ:None
        mm_fusion_op:sum
   mm_fusion_dropout:0.0
------
[data]
------
            txt_root:/vol/bitbucket/al4616/simmt/data/multi30k/en-de
            img_root:/vol/bitbucket/al4616/simmt/data/resnet50-256x256
           train_set:
                   src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/train.lc.norm.tok.en
                 image:/vol/bitbucket/al4616/simmt/data/resnet50-256x256/train-resnet50-res5c_relu-r256-c256-l2norm.npy
                   trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/train.lc.norm.tok.bpe.en
             val_set:
                   src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/val.lc.norm.tok.en
                 image:/vol/bitbucket/al4616/simmt/data/resnet50-256x256/val-resnet50-res5c_relu-r256-c256-l2norm.npy
                   trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/val.lc.norm.tok.bpe.en
test_2016_flickr_set:
                   src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/test_2016_flickr.lc.norm.tok.en
                 image:/vol/bitbucket/al4616/simmt/data/resnet50-256x256/test_2016_flickr-resnet50-res5c_relu-r256-c256-l2norm.npy
                   trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/test_2016_flickr.lc.norm.tok.bpe.en
test_2017_flickr_set:
                   src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/test_2017_flickr.lc.norm.tok.en
                 image:/vol/bitbucket/al4616/simmt/data/resnet50-256x256/test_2017_flickr-resnet50-res5c_relu-r256-c256-l2norm.npy
                   trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/test_2017_flickr.lc.norm.tok.bpe.en
------------
[vocabulary]
------------
                 src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/train.lc.norm.tok.vocab.en
                 trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/train.lc.norm.tok.bpe.vocab.en
----------------------------------------------------------------------

Python 3.7.7 -- torch 1.4.0 with CUDA 10.1 (on machine 'cloud-vm-40-190.doc.ic.ac.uk')
nmtpytorch 4.1.0
DeviceManager(cuda:0, n_gpu=1)
Seed for further reproducibility: 1590005827
SLURM Job ID: 6322
Loading dataset(s)
Initializing dataset for 'src'...
Dataset src with revert = False
0sents [00:00, ?sents/s]16878sents [00:00, 168677.21sents/s]29000sents [00:00, 160097.21sents/s]
Initializing dataset for 'image'...
Dataset image with revert = False
slurmstepd: error: *** JOB 6322 ON cloud-vm-40-190 CANCELLED AT 2020-05-20T21:17:09 ***
Initializing dataset for 'trg'...
Dataset trg with revert = False
0sents [00:00, ?sents/s]1436sents [00:00, 8520.28sents/s]14319sents [00:00, 53322.73sents/s]29000sents [00:00, 77997.33sents/s]
MultimodalDataset - (2 source(s) / 1 target(s))
  Sampler type: bucket, bucket_by: src
  Sources:
    --> TextDataset 'train.lc.norm.tok.en' (29000 sentences)
    --> NumpyDataset 'train-resnet50-res5c_relu-r256-c256-l2norm.npy' (29000 samples)

  Targets:
    --> TextDataset 'train.lc.norm.tok.bpe.en' (29000 sentences)

Initializing dataset for 'src'...
Dataset src with revert = False
0sents [00:00, ?sents/s]1014sents [00:00, 32599.47sents/s]
Initializing dataset for 'image'...
Dataset image with revert = False
Initializing dataset for 'trg'...
Dataset trg with revert = False
0sents [00:00, ?sents/s]1014sents [00:00, 95154.47sents/s]
MultimodalDataset - (2 source(s) / 1 target(s))
  Sampler type: bucket, bucket_by: src
  Sources:
    --> TextDataset 'val.lc.norm.tok.en' (1014 sentences)
    --> NumpyDataset 'val-resnet50-res5c_relu-r256-c256-l2norm.npy' (1014 samples)

  Targets:
    --> TextDataset 'val.lc.norm.tok.bpe.en' (1014 sentences)

Initializing dataset for 'src'...
Dataset src with revert = False
0sents [00:00, ?sents/s]1014sents [00:00, 115245.62sents/s]
Initializing dataset for 'image'...
Dataset image with revert = False
Skipping 'trg' as target
MultimodalDataset - (2 source(s) / 0 target(s))
  Sampler type: bucket, bucket_by: src
  Sources:
    --> TextDataset 'val.lc.norm.tok.en' (1014 sentences)
    --> NumpyDataset 'val-resnet50-res5c_relu-r256-c256-l2norm.npy' (1014 samples)


Ignoring batch_size 32 for simultaneous greedy search
SimultaneousWaitKNMT(
  (encoders): ModuleDict(
    (image): VisualFeaturesEncoder(
      (output): Sequential(
        (0): FF(in_features=2048, out_features=320, activ=tanh, bias=True, bias_zero=True)
        (1): Dropout(p=0.5, inplace=False)
      )
    )
    (src): TextEncoder(
      (do_emb): Dropout(p=0.4, inplace=False)
      (emb): Embedding(9797, 200, padding_idx=0)
      (enc): GRU(200, 320, num_layers=2)
      (output): Sequential(
        (0): Dropout(p=0.5, inplace=False)
      )
    )
  )
  (dec): SimultaneousConditionalDecoder(
    (emb): Embedding(4798, 200, padding_idx=0)
    (att): ModuleDict(
      (image): MLPAttention(
        (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
        (mlp): Linear(in_features=320, out_features=1, bias=False)
      )
      (src): MLPAttention(
        (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
        (mlp): Linear(in_features=320, out_features=1, bias=False)
      )
    )
    (fusion): Sequential(
      (0): Fusion(type=sum, adaptor=<function Fusion.__init__.<locals>.<lambda> at 0x7f72056f0440>, activ=None)
    )
    (dec0): GRUCell(200, 320)
    (dec1): GRUCell(320, 320)
    (do_out): Dropout(p=0.5, inplace=False)
    (hid2out): FF(in_features=840, out_features=200, activ=tanh, bias=True, bias_zero=True)
    (out2prob): FF(in_features=200, out_features=4798, activ=linear, bias=True, bias_zero=True)
    (nll_loss): NLLLoss()
  )
)
Vocabulary of 9797 items ('train.lc.norm.tok.vocab.en')
Vocabulary of 4798 items ('train.lc.norm.tok.bpe.vocab.en')
# parameters: 6.60M (6.60M learnable)

Optimizer => adam (lr: 0.0004, weight_decay: 1e-05, g_clip: 1, lr_decay: (patience=2, factor=0.5))
TensorBoard is active
Training started on 20-05-2020 21:17:24
Starting Epoch 1
Epoch 1 - update         30 => loss:   6.116 (#OOM: 0)
