-------
[train]
-------
         num_workers:0
          pin_memory:False
                seed:1590431243
               gclip:1
              l2_reg:1e-05
            patience:10
           optimizer:adam
                  lr:0.0004
            lr_decay:plateau
     lr_decay_revert:False
     lr_decay_factor:0.5
   lr_decay_patience:2
        lr_decay_min:1e-06
          model_type:SimultaneousWaitKNMT
            momentum:0.0
            nesterov:False
           disp_freq:30
          batch_size:64
          max_epochs:100
      max_iterations:1000000
        eval_metrics:bleu,loss
        eval_filters:
             de-hyphen
     eval_batch_size:32
           eval_freq:0
        eval_max_len:100
          eval_start:1
           eval_zero:False
   save_best_metrics:True
           save_path:/homes/al4616/experiments/simnmt/nmtpy/bpe_models/en-en
    save_optim_state:False
     checkpoint_freq:5000
       n_checkpoints:0
     tensorboard_dir:/homes/al4616/experiments/simnmt/nmtpy/bpe_models/en-en/tb_dir
     pretrained_file:
   pretrained_layers:
       freeze_layers:
          handle_oom:False
           subfolder:en-en-multimodal-w2bpe-wait1
              exp_id:simultaneouswaitknmt-re7691
------
[vars]
------
                  sl:en
                  tl:de
-------
[model]
-------
            att_type:mlp
      att_bottleneck:hid
             enc_dim:320
   enc_bidirectional:False
             dec_dim:320
             emb_dim:200
         dropout_emb:0.4
         dropout_ctx:0.5
         dropout_out:0.5
          n_encoders:2
            tied_emb:2way
             max_len:None
           out_logic:deep
           direction:src:Text, image:Numpy -> trg:Text
        sampler_type:bucket
           bucket_by:src
     translator_args:
                     k:1
         aux_dropout:0.5
        aux_proj_dim:320
      aux_proj_activ:tanh
             aux_dim:2048
       dec_inp_activ:None
        mm_fusion_op:sum
   mm_fusion_dropout:0.0
------
[data]
------
            txt_root:/vol/bitbucket/al4616/simmt/data/multi30k/en-de
            img_root:/vol/bitbucket/al4616/simmt/data/resnet50-256x256
           train_set:
                   src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/train.lc.norm.tok.en
                 image:/vol/bitbucket/al4616/simmt/data/resnet50-256x256/train-resnet50-res5c_relu-r256-c256-l2norm.npy
                   trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/train.lc.norm.tok.bpe.en
             val_set:
                   src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/val.lc.norm.tok.en
                 image:/vol/bitbucket/al4616/simmt/data/resnet50-256x256/val-resnet50-res5c_relu-r256-c256-l2norm.npy
                   trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/val.lc.norm.tok.bpe.en
test_2016_flickr_set:
                   src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/test_2016_flickr.lc.norm.tok.en
                 image:/vol/bitbucket/al4616/simmt/data/resnet50-256x256/test_2016_flickr-resnet50-res5c_relu-r256-c256-l2norm.npy
                   trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/test_2016_flickr.lc.norm.tok.bpe.en
test_2017_flickr_set:
                   src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/test_2017_flickr.lc.norm.tok.en
                 image:/vol/bitbucket/al4616/simmt/data/resnet50-256x256/test_2017_flickr-resnet50-res5c_relu-r256-c256-l2norm.npy
                   trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/test_2017_flickr.lc.norm.tok.bpe.en
------------
[vocabulary]
------------
                 src:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/train.lc.norm.tok.vocab.en
                 trg:/vol/bitbucket/al4616/simmt/data/multi30k/en-de/train.lc.norm.tok.bpe.vocab.en
----------------------------------------------------------------------

Python 3.7.7 -- torch 1.4.0 with CUDA 10.1 (on machine 'sicklebill.doc.ic.ac.uk')
nmtpytorch 4.1.0
DeviceManager(cuda:0, n_gpu=1)
Seed for further reproducibility: 1590431243
SLURM Job ID: 6634
Loading dataset(s)
Initializing dataset for 'src'...
Dataset src with revert = False
0sents [00:00, ?sents/s]468sents [00:00, 4663.68sents/s]1158sents [00:00, 5779.73sents/s]2315sents [00:00, 7706.45sents/s]3472sents [00:00, 7688.08sents/s]4629sents [00:00, 7787.48sents/s]5786sents [00:00, 7772.48sents/s]6943sents [00:00, 7657.63sents/s]8100sents [00:01, 7912.99sents/s]9331sents [00:01, 8303.34sents/s]10562sents [00:01, 8567.93sents/s]11793sents [00:01, 8803.67sents/s]13024sents [00:01, 8641.60sents/s]14255sents [00:01, 8564.60sents/s]15486sents [00:01, 8432.71sents/s]16717sents [00:02, 8348.98sents/s]17948sents [00:02, 8300.69sents/s]19179sents [00:02, 8265.63sents/s]20410sents [00:02, 8326.20sents/s]21641sents [00:02, 8335.80sents/s]22872sents [00:02, 8239.24sents/s]24103sents [00:02, 8273.46sents/s]25334sents [00:03, 8350.91sents/s]26565sents [00:03, 8446.57sents/s]27796sents [00:03, 8538.40sents/s]29000sents [00:03, 8618.63sents/s]
Initializing dataset for 'image'...
Dataset image with revert = False
Initializing dataset for 'trg'...
Dataset trg with revert = False
0sents [00:00, ?sents/s]973sents [00:00, 9721.23sents/s]1946sents [00:00, 9220.59sents/s]3072sents [00:00, 9875.64sents/s]4198sents [00:00, 10210.39sents/s]5324sents [00:00, 10387.45sents/s]6450sents [00:00, 10413.26sents/s]7576sents [00:00, 10466.33sents/s]8702sents [00:00, 10521.90sents/s]9828sents [00:00, 10413.05sents/s]10991sents [00:01, 10528.65sents/s]12154sents [00:01, 10528.33sents/s]13317sents [00:01, 10524.35sents/s]14480sents [00:01, 10542.51sents/s]15643sents [00:01, 10570.20sents/s]16806sents [00:01, 10595.52sents/s]17969sents [00:01, 10603.23sents/s]19132sents [00:01, 10536.31sents/s]20295sents [00:01, 10570.01sents/s]21458sents [00:02, 10591.95sents/s]22621sents [00:02, 10607.96sents/s]23784sents [00:02, 10653.08sents/s]24947sents [00:02, 10665.05sents/s]26110sents [00:02, 10642.54sents/s]27273sents [00:02, 10627.91sents/s]28436sents [00:02, 10634.17sents/s]29000sents [00:02, 10637.61sents/s]
MultimodalDataset - (2 source(s) / 1 target(s))
  Sampler type: bucket, bucket_by: src
  Sources:
    --> TextDataset 'train.lc.norm.tok.en' (29000 sentences)
    --> NumpyDataset 'train-resnet50-res5c_relu-r256-c256-l2norm.npy' (29000 samples)

  Targets:
    --> TextDataset 'train.lc.norm.tok.bpe.en' (29000 sentences)

Initializing dataset for 'src'...
Dataset src with revert = False
0sents [00:00, ?sents/s]1014sents [00:00, 11106.62sents/s]
Initializing dataset for 'image'...
Dataset image with revert = False
Initializing dataset for 'trg'...
Dataset trg with revert = False
0sents [00:00, ?sents/s]884sents [00:00, 8822.00sents/s]1014sents [00:00, 8778.30sents/s]
MultimodalDataset - (2 source(s) / 1 target(s))
  Sampler type: bucket, bucket_by: src
  Sources:
    --> TextDataset 'val.lc.norm.tok.en' (1014 sentences)
    --> NumpyDataset 'val-resnet50-res5c_relu-r256-c256-l2norm.npy' (1014 samples)

  Targets:
    --> TextDataset 'val.lc.norm.tok.bpe.en' (1014 sentences)

Initializing dataset for 'src'...
Dataset src with revert = False
0sents [00:00, ?sents/s]1014sents [00:00, 10687.44sents/s]
Initializing dataset for 'image'...
Dataset image with revert = False
Skipping 'trg' as target
MultimodalDataset - (2 source(s) / 0 target(s))
  Sampler type: bucket, bucket_by: src
  Sources:
    --> TextDataset 'val.lc.norm.tok.en' (1014 sentences)
    --> NumpyDataset 'val-resnet50-res5c_relu-r256-c256-l2norm.npy' (1014 samples)


Ignoring batch_size 32 for simultaneous greedy search
SimultaneousWaitKNMT(
  (encoders): ModuleDict(
    (image): VisualFeaturesEncoder(
      (output): Sequential(
        (0): FF(in_features=2048, out_features=320, activ=tanh, bias=True, bias_zero=True)
        (1): Dropout(p=0.5, inplace=False)
      )
    )
    (src): TextEncoder(
      (do_emb): Dropout(p=0.4, inplace=False)
      (emb): Embedding(9797, 200, padding_idx=0)
      (enc): GRU(200, 320, num_layers=2)
      (output): Sequential(
        (0): Dropout(p=0.5, inplace=False)
      )
    )
  )
  (dec): SimultaneousConditionalDecoder(
    (emb): Embedding(4798, 200, padding_idx=0)
    (att): ModuleDict(
      (image): MLPAttention(
        (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
        (mlp): Linear(in_features=320, out_features=1, bias=False)
      )
      (src): MLPAttention(
        (hid2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2ctx): Linear(in_features=320, out_features=320, bias=False)
        (ctx2hid): Linear(in_features=320, out_features=320, bias=False)
        (mlp): Linear(in_features=320, out_features=1, bias=False)
      )
    )
    (fusion): Sequential(
      (0): Fusion(type=sum, adaptor=<function Fusion.__init__.<locals>.<lambda> at 0x7fd02ac41440>, activ=None)
    )
    (dec0): GRUCell(200, 320)
    (dec1): GRUCell(320, 320)
    (do_out): Dropout(p=0.5, inplace=False)
    (hid2out): FF(in_features=840, out_features=200, activ=tanh, bias=True, bias_zero=True)
    (out2prob): FF(in_features=200, out_features=4798, activ=linear, bias=True, bias_zero=True)
    (nll_loss): NLLLoss()
  )
)
Vocabulary of 9797 items ('train.lc.norm.tok.vocab.en')
Vocabulary of 4798 items ('train.lc.norm.tok.bpe.vocab.en')
# parameters: 6.60M (6.60M learnable)

Optimizer => adam (lr: 0.0004, weight_decay: 1e-05, g_clip: 1, lr_decay: (patience=2, factor=0.5))
TensorBoard is active
Training started on 25-05-2020 19:28:43
Starting Epoch 1
Epoch 1 - update         30 => loss:   6.210 (#OOM: 0)
Epoch 1 - update         60 => loss:   5.558 (#OOM: 0)
Epoch 1 - update         90 => loss:   4.898 (#OOM: 0)
Epoch 1 - update        120 => loss:   4.722 (#OOM: 0)
Epoch 1 - update        150 => loss:   3.842 (#OOM: 0)
Epoch 1 - update        180 => loss:   4.004 (#OOM: 0)
Epoch 1 - update        210 => loss:   3.864 (#OOM: 0)
slurmstepd: error: *** JOB 6634 ON sicklebill CANCELLED AT 2020-05-25T19:35:36 ***
